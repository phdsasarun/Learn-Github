{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLpKMI/D3Fa4/Wpw7BkON5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phdsasarun/Learn-Github/blob/main/Modi_CKD_0505.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î‡πÇ‡∏£‡∏Ñ‡πÑ‡∏ï‡πÄ‡∏£‡∏∑‡πâ‡∏≠‡∏£‡∏±‡∏á (CKD) ‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡πÄ‡∏ö‡∏≤‡∏´‡∏ß‡∏≤‡∏ô\n",
        "# ‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ Machine Learning\n",
        "\n",
        "# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Libraries ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\n",
        "!pip install pandas numpy scikit-learn tensorflow matplotlib seaborn plotly\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# 1. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
        "print(\"=== ‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ===\")\n",
        "# ‡πÉ‡∏ä‡πâ gdown ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å Google Drive\n",
        "!pip install gdown\n",
        "import gdown\n",
        "\n",
        "# ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å Google Drive\n",
        "file_id = \"12tU2nSdEy7OfbZtHr8pxUuuh00KxWkod\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "output = \"kidney_disease_dataset.csv\"\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
        "df = pd.read_csv(output)\n",
        "print(f\"‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {df.shape}\")\n",
        "print(\"\\n‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 5 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å:\")\n",
        "print(df.head())\n",
        "\n",
        "# 2. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£\n",
        "print(\"\\n=== ‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ ===\")\n",
        "selected_columns = [\n",
        "    'age',  # Age of the patient\n",
        "    'bp',   # Blood pressure (mm/Hg)\n",
        "    'al',   # Albumin in urine\n",
        "    'bgr',  # Random blood glucose level (mg/dl)\n",
        "    'sc',   # Serum creatinine (mg/dl)\n",
        "    'hemo', # Hemoglobin level (gms)\n",
        "    'pcv',  # Packed Cell Volume (‡πÉ‡∏ä‡πâ‡πÅ‡∏ó‡∏ô eGFR)\n",
        "    'rc',   # Red Blood Cell Count (‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏ó‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Cholesterol)\n",
        "    'classification'  # Target variable\n",
        "]\n",
        "\n",
        "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
        "print(\"‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:\")\n",
        "print(df.columns.tolist())\n",
        "\n",
        "# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á\n",
        "available_columns = [col for col in selected_columns if col in df.columns]\n",
        "print(f\"\\n‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ: {available_columns}\")\n",
        "\n",
        "df_selected = df[available_columns].copy()\n",
        "\n",
        "# 3. ‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏£‡∏ß‡∏à‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Exploratory Data Analysis)\n",
        "print(\"\\n=== ‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏£‡∏ß‡∏à‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ===\")\n",
        "print(\"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô:\")\n",
        "print(df_selected.describe())\n",
        "\n",
        "print(\"\\n‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ:\")\n",
        "print(df_selected.isnull().sum())\n",
        "\n",
        "print(\"\\n‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡∏Å‡πÅ‡∏à‡∏á‡∏Ç‡∏≠‡∏á Target Variable:\")\n",
        "print(df_selected['classification'].value_counts())\n",
        "\n",
        "# 4. ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
        "print(\"\\n=== ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ===\")\n",
        "\n",
        "# ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡πà‡∏≤ categorical ‡πÄ‡∏õ‡πá‡∏ô numerical\n",
        "label_encoders = {}\n",
        "for column in df_selected.columns:\n",
        "    if df_selected[column].dtype == 'object':\n",
        "        if column != 'classification':\n",
        "            le = LabelEncoder()\n",
        "            df_selected[column] = le.fit_transform(df_selected[column].astype(str))\n",
        "            label_encoders[column] = le\n",
        "\n",
        "# ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ\n",
        "df_selected = df_selected.fillna(df_selected.median())\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á CKD Risk Levels (5 ‡∏£‡∏∞‡∏î‡∏±‡∏ö)\n",
        "def create_ckd_risk_levels(row):\n",
        "    \"\"\"\n",
        "    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á CKD ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏•‡∏¥‡∏ô‡∏¥‡∏Å\n",
        "    ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏î‡∏ú‡∏•:\n",
        "    - Age: >65 (‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á)\n",
        "    - BP: >140/90 (‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á)\n",
        "    - Serum Creatinine: >1.5 (‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á)\n",
        "    - Albumin: >2+ (‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á)\n",
        "    - Hemoglobin: <10 (‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á)\n",
        "    \"\"\"\n",
        "    risk_score = 0\n",
        "\n",
        "    # Age factor\n",
        "    if 'age' in row.index and row['age'] > 65:\n",
        "        risk_score += 2\n",
        "    elif 'age' in row.index and row['age'] > 45:\n",
        "        risk_score += 1\n",
        "\n",
        "    # Blood pressure factor\n",
        "    if 'bp' in row.index and row['bp'] > 140:\n",
        "        risk_score += 2\n",
        "    elif 'bp' in row.index and row['bp'] > 120:\n",
        "        risk_score += 1\n",
        "\n",
        "    # Serum creatinine factor\n",
        "    if 'sc' in row.index and row['sc'] > 1.5:\n",
        "        risk_score += 2\n",
        "    elif 'sc' in row.index and row['sc'] > 1.2:\n",
        "        risk_score += 1\n",
        "\n",
        "    # Albumin factor\n",
        "    if 'al' in row.index and row['al'] > 2:\n",
        "        risk_score += 2\n",
        "    elif 'al' in row.index and row['al'] > 1:\n",
        "        risk_score += 1\n",
        "\n",
        "    # Hemoglobin factor\n",
        "    if 'hemo' in row.index and row['hemo'] < 10:\n",
        "        risk_score += 2\n",
        "    elif 'hemo' in row.index and row['hemo'] < 12:\n",
        "        risk_score += 1\n",
        "\n",
        "    # Convert to 5-level classification\n",
        "    if risk_score == 0:\n",
        "        return 1  # No Disease\n",
        "    elif risk_score <= 2:\n",
        "        return 2  # Low Risk\n",
        "    elif risk_score <= 4:\n",
        "        return 3  # Moderate Risk\n",
        "    elif risk_score <= 6:\n",
        "        return 4  # High Risk\n",
        "    else:\n",
        "        return 5  # Severe Disease\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á target variable ‡πÅ‡∏ö‡∏ö 5 ‡∏£‡∏∞‡∏î‡∏±‡∏ö\n",
        "if 'classification' in df_selected.columns:\n",
        "    # ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• classification ‡πÄ‡∏î‡∏¥‡∏°‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô 5 ‡∏£‡∏∞‡∏î‡∏±‡∏ö\n",
        "    unique_classes = df_selected['classification'].unique()\n",
        "    if len(unique_classes) == 2:  # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô binary classification\n",
        "        # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô 5 ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ clinical parameters\n",
        "        df_selected['ckd_risk_level'] = df_selected.apply(create_ckd_risk_levels, axis=1)\n",
        "    else:\n",
        "        df_selected['ckd_risk_level'] = df_selected['classification']\n",
        "else:\n",
        "    df_selected['ckd_risk_level'] = df_selected.apply(create_ckd_risk_levels, axis=1)\n",
        "\n",
        "# ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡∏Å‡πÅ‡∏à‡∏á‡∏Ç‡∏≠‡∏á CKD Risk Levels\n",
        "print(\"\\n=== ‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡∏Å‡πÅ‡∏à‡∏á‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á CKD ===\")\n",
        "risk_levels = {\n",
        "    1: \"No Disease (‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏†‡∏≤‡∏ß‡∏∞‡πÇ‡∏£‡∏Ñ‡πÑ‡∏ï‡πÄ‡∏£‡∏∑‡πâ‡∏≠‡∏£‡∏±‡∏á)\",\n",
        "    2: \"Low Risk (‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ï‡πà‡∏≥)\",\n",
        "    3: \"Moderate Risk (‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á)\",\n",
        "    4: \"High Risk (‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á)\",\n",
        "    5: \"Severe Disease (‡πÇ‡∏£‡∏Ñ‡πÑ‡∏ï‡πÄ‡∏£‡∏∑‡πâ‡∏≠‡∏£‡∏±‡∏á‡∏£‡πâ‡∏≤‡∏¢‡πÅ‡∏£‡∏á)\"\n",
        "}\n",
        "\n",
        "risk_distribution = df_selected['ckd_risk_level'].value_counts().sort_index()\n",
        "print(\"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏∞‡∏î‡∏±‡∏ö:\")\n",
        "for level, count in risk_distribution.items():\n",
        "    print(f\"‡∏£‡∏∞‡∏î‡∏±‡∏ö {level}: {risk_levels[level]} = {count} ‡∏Ñ‡∏ô ({count/len(df_selected)*100:.1f}%)\")\n",
        "\n",
        "# 5. ‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏£‡∏≤‡∏ü\n",
        "print(\"\\n=== ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• ===\")\n",
        "\n",
        "# ‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡∏Å‡πÅ‡∏à‡∏á‡∏Ç‡∏≠‡∏á CKD Risk Levels\n",
        "fig = make_subplots(\n",
        "    rows=2, cols=2,\n",
        "    subplot_titles=('‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡∏Å‡πÅ‡∏à‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á CKD', '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏≠‡∏≤‡∏¢‡∏∏‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á',\n",
        "                   '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡∏±‡∏ô‡πÇ‡∏•‡∏´‡∏¥‡∏ï‡πÅ‡∏•‡∏∞ Creatinine', '‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡∏Å‡πÅ‡∏à‡∏á‡∏ï‡∏≤‡∏°‡πÄ‡∏û‡∏® (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)'),\n",
        "    specs=[[{\"type\": \"bar\"}, {\"type\": \"box\"}],\n",
        "           [{\"type\": \"scatter\"}, {\"type\": \"pie\"}]]\n",
        ")\n",
        "\n",
        "# ‡∏Å‡∏£‡∏≤‡∏é‡πÅ‡∏ó‡πà‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡∏Å‡πÅ‡∏à‡∏á\n",
        "labels = [f\"Level {i}: {risk_levels[i].split('(')[0].strip()}\" for i in range(1, 6)]\n",
        "values = [risk_distribution.get(i, 0) for i in range(1, 6)]\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Bar(x=labels, y=values, name=\"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢\"),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "# Box plot ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡∏≤‡∏¢‡∏∏‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á\n",
        "if 'age' in df_selected.columns:\n",
        "    fig.add_trace(\n",
        "        go.Box(y=df_selected['age'], x=df_selected['ckd_risk_level'], name=\"‡∏≠‡∏≤‡∏¢‡∏∏\"),\n",
        "        row=1, col=2\n",
        "    )\n",
        "\n",
        "# Scatter plot ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡∏±‡∏ô‡πÇ‡∏•‡∏´‡∏¥‡∏ï‡πÅ‡∏•‡∏∞ Creatinine\n",
        "if 'bp' in df_selected.columns and 'sc' in df_selected.columns:\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=df_selected['bp'], y=df_selected['sc'],\n",
        "                  mode='markers',\n",
        "                  marker=dict(color=df_selected['ckd_risk_level'], colorscale='Viridis'),\n",
        "                  name=\"BP vs Creatinine\"),\n",
        "        row=2, col=1\n",
        "    )\n",
        "\n",
        "# Pie chart ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡∏Å‡πÅ‡∏à‡∏á\n",
        "fig.add_trace(\n",
        "    go.Pie(labels=labels, values=values, name=\"‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô\"),\n",
        "    row=2, col=2\n",
        ")\n",
        "\n",
        "fig.update_layout(height=800, title_text=\"‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• CKD Risk Analysis\")\n",
        "fig.show()\n",
        "\n",
        "# 6. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Machine Learning\n",
        "print(\"\\n=== ‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Machine Learning ===\")\n",
        "\n",
        "# ‡πÅ‡∏¢‡∏Å features ‡πÅ‡∏•‡∏∞ target\n",
        "feature_columns = [col for col in df_selected.columns if col not in ['classification', 'ckd_risk_level']]\n",
        "X = df_selected[feature_columns]\n",
        "y = df_selected['ckd_risk_level']\n",
        "\n",
        "print(f\"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Features: {len(feature_columns)}\")\n",
        "print(f\"Features: {feature_columns}\")\n",
        "print(f\"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: {len(X)}\")\n",
        "\n",
        "# ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô train ‡πÅ‡∏•‡∏∞ test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Training: {X_train_scaled.shape}\")\n",
        "print(f\"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Testing: {X_test_scaled.shape}\")\n",
        "\n",
        "# 7. Logistic Regression Model\n",
        "print(\"\\n=== Logistic Regression Model ===\")\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• Logistic Regression\n",
        "lr_model = LogisticRegression(multi_class='ovr', max_iter=1000, random_state=42)\n",
        "lr_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•\n",
        "y_pred_lr = lr_model.predict(X_test_scaled)\n",
        "y_pred_proba_lr = lr_model.predict_proba(X_test_scaled)\n",
        "\n",
        "# ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•\n",
        "lr_accuracy = accuracy_score(y_test, y_pred_lr)\n",
        "print(f\"Logistic Regression Accuracy: {lr_accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report (Logistic Regression):\")\n",
        "print(classification_report(y_test, y_pred_lr,\n",
        "                          target_names=[risk_levels[i] for i in sorted(y.unique())]))\n",
        "\n",
        "# Confusion Matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
        "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=[f\"Level {i}\" for i in sorted(y.unique())],\n",
        "            yticklabels=[f\"Level {i}\" for i in sorted(y.unique())])\n",
        "plt.title('Confusion Matrix - Logistic Regression')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# Feature Importance ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Logistic Regression\n",
        "feature_importance_lr = np.abs(lr_model.coef_).mean(axis=0)\n",
        "feature_df_lr = pd.DataFrame({\n",
        "    'Feature': feature_columns,\n",
        "    'Importance': feature_importance_lr\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=feature_df_lr, x='Importance', y='Feature')\n",
        "plt.title('Feature Importance - Logistic Regression')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nTop 5 ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç Features (Logistic Regression):\")\n",
        "print(feature_df_lr.head())\n",
        "\n",
        "# 8. Neural Network (Deep Learning) Model\n",
        "print(\"\\n=== Neural Network (Deep Learning) Model ===\")\n",
        "\n",
        "# ‡πÅ‡∏õ‡∏•‡∏á target ‡πÄ‡∏õ‡πá‡∏ô categorical ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Neural Network\n",
        "num_classes = len(y.unique())\n",
        "y_train_cat = tf.keras.utils.to_categorical(y_train - 1, num_classes)  # -1 ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ class ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 1\n",
        "y_test_cat = tf.keras.utils.to_categorical(y_test - 1, num_classes)\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á Neural Network Model\n",
        "def create_nn_model(input_dim, num_classes):\n",
        "    model = Sequential([\n",
        "        Dense(128, input_dim=input_dim, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Dense(64, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Dense(32, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2),\n",
        "\n",
        "        Dense(16, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
        "nn_model = create_nn_model(X_train_scaled.shape[1], num_classes)\n",
        "print(\"Neural Network Architecture:\")\n",
        "nn_model.summary()\n",
        "\n",
        "# Callbacks ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.0001)\n",
        "\n",
        "# ‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
        "history = nn_model.fit(\n",
        "    X_train_scaled, y_train_cat,\n",
        "    validation_data=(X_test_scaled, y_test_cat),\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping, reduce_lr],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•\n",
        "y_pred_nn = nn_model.predict(X_test_scaled)\n",
        "y_pred_nn_classes = np.argmax(y_pred_nn, axis=1) + 1  # +1 ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ class ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 1\n",
        "\n",
        "# ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•\n",
        "nn_accuracy = accuracy_score(y_test, y_pred_nn_classes)\n",
        "print(f\"\\nNeural Network Accuracy: {nn_accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report (Neural Network):\")\n",
        "print(classification_report(y_test, y_pred_nn_classes,\n",
        "                          target_names=[risk_levels[i] for i in sorted(y.unique())]))\n",
        "\n",
        "# Confusion Matrix ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Neural Network\n",
        "plt.figure(figsize=(10, 8))\n",
        "cm_nn = confusion_matrix(y_test, y_pred_nn_classes)\n",
        "sns.heatmap(cm_nn, annot=True, fmt='d', cmap='Greens',\n",
        "            xticklabels=[f\"Level {i}\" for i in sorted(y.unique())],\n",
        "            yticklabels=[f\"Level {i}\" for i in sorted(y.unique())])\n",
        "plt.title('Confusion Matrix - Neural Network')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.bar(['Logistic Regression', 'Neural Network'], [lr_accuracy, nn_accuracy])\n",
        "plt.title('Model Comparison')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0, 1)\n",
        "for i, v in enumerate([lr_accuracy, nn_accuracy]):\n",
        "    plt.text(i, v + 0.01, f'{v:.4f}', ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 9. ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
        "print(\"\\n=== ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ===\")\n",
        "results_comparison = pd.DataFrame({\n",
        "    'Model': ['Logistic Regression', 'Neural Network'],\n",
        "    'Accuracy': [lr_accuracy, nn_accuracy],\n",
        "    'Training_Time': ['Fast', 'Moderate'],\n",
        "    'Interpretability': ['High', 'Low']\n",
        "})\n",
        "\n",
        "print(results_comparison)\n",
        "\n",
        "# 10. ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏î‡∏ú‡∏•‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ Item\n",
        "print(\"\\n=== ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏î‡∏ú‡∏•‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ Item ===\")\n",
        "criteria = {\n",
        "    'Age (‡∏≠‡∏≤‡∏¢‡∏∏)': {\n",
        "        '‡∏õ‡∏Å‡∏ï‡∏¥': '< 45 ‡∏õ‡∏µ',\n",
        "        '‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á': '45-65 ‡∏õ‡∏µ',\n",
        "        '‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á': '> 65 ‡∏õ‡∏µ'\n",
        "    },\n",
        "    'Blood Pressure (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡∏±‡∏ô‡πÇ‡∏•‡∏´‡∏¥‡∏ï)': {\n",
        "        '‡∏õ‡∏Å‡∏ï‡∏¥': '< 120/80 mmHg',\n",
        "        '‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á': '120-140/80-90 mmHg',\n",
        "        '‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á': '> 140/90 mmHg'\n",
        "    },\n",
        "    'Serum Creatinine (‡∏Ñ‡∏£‡∏µ‡∏≠‡∏≤‡∏ï‡∏¥‡∏ô‡∏¥‡∏ô)': {\n",
        "        '‡∏õ‡∏Å‡∏ï‡∏¥': '< 1.2 mg/dl',\n",
        "        '‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á': '1.2-1.5 mg/dl',\n",
        "        '‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á': '> 1.5 mg/dl'\n",
        "    },\n",
        "    'Albumin in Urine (‡πÇ‡∏õ‡∏£‡∏ï‡∏µ‡∏ô‡πÉ‡∏ô‡∏õ‡∏±‡∏™‡∏™‡∏≤‡∏ß‡∏∞)': {\n",
        "        '‡∏õ‡∏Å‡∏ï‡∏¥': 'Negative/Trace',\n",
        "        '‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á': '1+',\n",
        "        '‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á': '2+ ‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏õ'\n",
        "    },\n",
        "    'Hemoglobin (‡∏Æ‡∏µ‡πÇ‡∏°‡πÇ‡∏Å‡∏•‡∏ö‡∏¥‡∏ô)': {\n",
        "        '‡∏õ‡∏Å‡∏ï‡∏¥': '> 12 g/dl',\n",
        "        '‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á': '10-12 g/dl',\n",
        "        '‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á': '< 10 g/dl'\n",
        "    },\n",
        "    'Blood Glucose (‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏•‡πÉ‡∏ô‡πÄ‡∏•‡∏∑‡∏≠‡∏î)': {\n",
        "        '‡∏õ‡∏Å‡∏ï‡∏¥': '< 100 mg/dl',\n",
        "        '‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á': '100-125 mg/dl',\n",
        "        '‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á': '> 125 mg/dl'\n",
        "    }\n",
        "}\n",
        "\n",
        "for item, ranges in criteria.items():\n",
        "    print(f\"\\n{item}:\")\n",
        "    for level, range_val in ranges.items():\n",
        "        print(f\"  - {level}: {range_val}\")\n",
        "\n",
        "# 11. ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢\n",
        "print(\"\\n=== ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢ ===\")\n",
        "print(\"1. ‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡∏Å‡πÅ‡∏à‡∏á‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢:\")\n",
        "for level, count in risk_distribution.items():\n",
        "    percentage = count/len(df_selected)*100\n",
        "    print(f\"   - {risk_levels[level]}: {count} ‡∏Ñ‡∏ô ({percentage:.1f}%)\")\n",
        "\n",
        "print(f\"\\n2. ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•:\")\n",
        "print(f\"   - Logistic Regression: {lr_accuracy:.1%}\")\n",
        "print(f\"   - Neural Network: {nn_accuracy:.1%}\")\n",
        "\n",
        "if nn_accuracy > lr_accuracy:\n",
        "    print(f\"\\n3. Neural Network ‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤ Logistic Regression {(nn_accuracy-lr_accuracy)*100:.1f}%\")\n",
        "else:\n",
        "    print(f\"\\n3. Logistic Regression ‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤ Neural Network {(lr_accuracy-nn_accuracy)*100:.1f}%\")\n",
        "\n",
        "print(\"\\n4. ‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢:\")\n",
        "print(\"   Top 3 Features ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:\")\n",
        "for i, (_, row) in enumerate(feature_df_lr.head(3).iterrows()):\n",
        "    print(f\"   {i+1}. {row['Feature']}: {row['Importance']:.4f}\")\n",
        "\n",
        "print(\"\\n=== ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå ===\")\n",
        "\n",
        "# 12. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
        "print(\"\\n=== ‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ===\")\n",
        "\n",
        "# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢\n",
        "predictions_df = pd.DataFrame({\n",
        "    'Actual': y_test,\n",
        "    'Logistic_Regression': y_pred_lr,\n",
        "    'Neural_Network': y_pred_nn_classes\n",
        "})\n",
        "\n",
        "# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå\n",
        "predictions_df.to_csv('ckd_predictions.csv', index=False)\n",
        "results_comparison.to_csv('model_comparison.csv', index=False)\n",
        "feature_df_lr.to_csv('feature_importance.csv', index=False)\n",
        "\n",
        "print(\"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢:\")\n",
        "print(\"- ckd_predictions.csv: ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•\")\n",
        "print(\"- model_comparison.csv: ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÇ‡∏°‡πÄ‡∏î‡∏•\")\n",
        "print(\"- feature_importance.csv: ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á Features\")\n",
        "\n",
        "print(\"\\nüéâ ‡πÇ‡∏Ñ‡∏£‡∏á‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå! üéâ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Nht1Ts7BgBEu",
        "outputId": "4c7c908f-4a97-448e-9a39-073259fc41e5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.72.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (9.1.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "=== ‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ===\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.4.26)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12tU2nSdEy7OfbZtHr8pxUuuh00KxWkod\n",
            "To: /content/kidney_disease_dataset.csv\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.48M/5.48M [00:00<00:00, 19.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: (20538, 43)\n",
            "\n",
            "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 5 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å:\n",
            "   Age of the patient  Blood pressure (mm/Hg)  Specific gravity of urine  \\\n",
            "0                  54                     167                      1.023   \n",
            "1                  42                     127                      1.023   \n",
            "2                  38                     148                      1.016   \n",
            "3                   7                      98                      1.017   \n",
            "4                  67                     174                      1.015   \n",
            "\n",
            "   Albumin in urine  Sugar in urine Red blood cells in urine  \\\n",
            "0                 1               4                   normal   \n",
            "1                 3               2                   normal   \n",
            "2                 0               0                 abnormal   \n",
            "3                 4               0                 abnormal   \n",
            "4                 1               1                   normal   \n",
            "\n",
            "  Pus cells in urine Pus cell clumps in urine Bacteria in urine  \\\n",
            "0           abnormal              not present       not present   \n",
            "1             normal              not present           present   \n",
            "2             normal              not present       not present   \n",
            "3             normal              not present           present   \n",
            "4           abnormal              not present       not present   \n",
            "\n",
            "   Random blood glucose level (mg/dl)  ...  Smoking status  \\\n",
            "0                                  96  ...             yes   \n",
            "1                                  73  ...              no   \n",
            "2                                  77  ...              no   \n",
            "3                                 225  ...              no   \n",
            "4                                 376  ...             yes   \n",
            "\n",
            "   Body Mass Index (BMI)  Physical activity level  \\\n",
            "0                   25.3                      low   \n",
            "1                   20.6                 moderate   \n",
            "2                   38.4                     high   \n",
            "3                   24.7                     high   \n",
            "4                   17.6                     high   \n",
            "\n",
            "   Duration of diabetes mellitus (years)  Duration of hypertension (years)  \\\n",
            "0                                      4                                16   \n",
            "1                                      3                                13   \n",
            "2                                     11                                23   \n",
            "3                                     24                                 3   \n",
            "4                                     22                                24   \n",
            "\n",
            "   Cystatin C level  Urinary sediment microscopy results  \\\n",
            "0              0.67                               normal   \n",
            "1              0.55                             abnormal   \n",
            "2              2.37                             abnormal   \n",
            "3              2.54                             abnormal   \n",
            "4              1.90                               normal   \n",
            "\n",
            "   C-reactive protein (CRP) level Interleukin-6 (IL-6) level      Target  \n",
            "0                            4.88                      10.23  No_Disease  \n",
            "1                            4.49                      13.11    Low_Risk  \n",
            "2                            4.57                      13.27  No_Disease  \n",
            "3                            8.57                      12.36  No_Disease  \n",
            "4                            6.75                       1.46  No_Disease  \n",
            "\n",
            "[5 rows x 43 columns]\n",
            "\n",
            "=== ‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ ===\n",
            "‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:\n",
            "['Age of the patient', 'Blood pressure (mm/Hg)', 'Specific gravity of urine', 'Albumin in urine', 'Sugar in urine', 'Red blood cells in urine', 'Pus cells in urine', 'Pus cell clumps in urine', 'Bacteria in urine', 'Random blood glucose level (mg/dl)', 'Blood urea (mg/dl)', 'Serum creatinine (mg/dl)', 'Sodium level (mEq/L)', 'Potassium level (mEq/L)', 'Hemoglobin level (gms)', 'Packed cell volume (%)', 'White blood cell count (cells/cumm)', 'Red blood cell count (millions/cumm)', 'Hypertension (yes/no)', 'Diabetes mellitus (yes/no)', 'Coronary artery disease (yes/no)', 'Appetite (good/poor)', 'Pedal edema (yes/no)', 'Anemia (yes/no)', 'Estimated Glomerular Filtration Rate (eGFR)', 'Urine protein-to-creatinine ratio', 'Urine output (ml/day)', 'Serum albumin level', 'Cholesterol level', 'Parathyroid hormone (PTH) level', 'Serum calcium level', 'Serum phosphate level', 'Family history of chronic kidney disease', 'Smoking status', 'Body Mass Index (BMI)', 'Physical activity level', 'Duration of diabetes mellitus (years)', 'Duration of hypertension (years)', 'Cystatin C level', 'Urinary sediment microscopy results', 'C-reactive protein (CRP) level', 'Interleukin-6 (IL-6) level', 'Target']\n",
            "\n",
            "‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ: []\n",
            "\n",
            "=== ‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏£‡∏ß‡∏à‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ===\n",
            "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Cannot describe a DataFrame without columns",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-312867809>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n=== ‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏£‡∏ß‡∏à‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_selected\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdescribe\u001b[0;34m(self, percentiles, include, exclude)\u001b[0m\n\u001b[1;32m  11974\u001b[0m         \u001b[0mmax\u001b[0m            \u001b[0mNaN\u001b[0m      \u001b[0;36m3.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11975\u001b[0m         \"\"\"\n\u001b[0;32m> 11976\u001b[0;31m         return describe_ndframe(\n\u001b[0m\u001b[1;32m  11977\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11978\u001b[0m             \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/methods/describe.py\u001b[0m in \u001b[0;36mdescribe_ndframe\u001b[0;34m(obj, include, exclude, percentiles)\u001b[0m\n\u001b[1;32m     89\u001b[0m         )\n\u001b[1;32m     90\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         describer = DataFrameDescriber(\n\u001b[0m\u001b[1;32m     92\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/methods/describe.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot describe a DataFrame without columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot describe a DataFrame without columns"
          ]
        }
      ]
    }
  ]
}